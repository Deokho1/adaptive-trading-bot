#!/usr/bin/env python
"""
Adaptive Trading Bot CLI Tool

Usage:
  python cli.py collect <symbol> <interval> <days>    # ë°ì´í„° ìˆ˜ì§‘
  python cli.py list                                  # ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸
  python cli.py analyze <file>                        # ë°ì´í„° ë¶„ì„
  python cli.py test                                  # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime, timedelta
import pytz

# Add project path
sys.path.append(str(Path(__file__).parent))

def parse_date(date_str):
    """ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
    if not date_str:
        return None
    
    try:
        # YYYY-MM-DD í˜•ì‹
        if len(date_str) == 10:
            dt = datetime.strptime(date_str, "%Y-%m-%d")
        # YYYY-MM-DD HH:MM í˜•ì‹
        elif len(date_str) == 16:
            dt = datetime.strptime(date_str, "%Y-%m-%d %H:%M")
        # YYYY-MM-DD HH:MM:SS í˜•ì‹  
        elif len(date_str) == 19:
            dt = datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S")
        else:
            raise ValueError("Invalid date format")
            
        # UTCë¡œ ë³€í™˜
        return pytz.UTC.localize(dt)
        
    except ValueError:
        raise ValueError(f"Invalid date format: {date_str}. Use YYYY-MM-DD, YYYY-MM-DD HH:MM, or YYYY-MM-DD HH:MM:SS")

def collect_data(symbol, interval, days=None, start_date=None, end_date=None):
    """ë°ì´í„° ìˆ˜ì§‘ + ìë™ ê²€ì¦ (ë‚ ì§œ ë²”ìœ„ ì§€ì›)"""
    
    # ë‚ ì§œ ì„¤ì • ë¡œì§
    if start_date or end_date:
        # íŠ¹ì • ë‚ ì§œ ë²”ìœ„ ì§€ì •
        if start_date and end_date:
            start_dt = parse_date(start_date)
            end_dt = parse_date(end_date)
            period_desc = f"{start_date} ~ {end_date}"
        elif start_date:
            start_dt = parse_date(start_date)
            end_dt = datetime.now(pytz.UTC)
            period_desc = f"{start_date} ~ now"
        else:  # end_dateë§Œ ì§€ì •
            end_dt = parse_date(end_date)
            start_dt = end_dt - timedelta(days=days or 7)
            period_desc = f"{days or 7} days ~ {end_date}"
    else:
        # ê¸°ì¡´ ë°©ì‹: í˜„ì¬ë¶€í„° Nì¼ ì „
        end_dt = datetime.now(pytz.UTC)
        start_dt = end_dt - timedelta(days=days or 1)
        period_desc = f"{days or 1} days back"
    
    print(f"Collecting {symbol} {interval} data for {period_desc}...")
    
    try:
        from data_tools.build_datasets import DatasetBuilder
        from data_tools.verify_integrity import DataIntegrityVerifier
        
        builder = DatasetBuilder()
        
        # 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ + ì €ì¥
        result = builder.build_single_dataset(
            exchange="upbit",
            symbol=symbol,
            interval=interval,
            start_date=start_dt,
            end_date=end_dt,
            save_formats=["csv"]
        )
        
        if result["status"] == "completed":
            print(f"âœ… Success: {result['candles_collected']} candles collected")
            print(f"ğŸ“ Files created: {len(result['files_created'])}")
            
            # 2ë‹¨ê³„: ìë™ ê²€ì¦
            if result['files_created']:
                print("ğŸ” Starting data verification...")
                verifier = DataIntegrityVerifier()
                
                for file_path in result['files_created']:
                    # CSV íŒŒì¼ë§Œ ê²€ì¦ (ë©”íƒ€ë°ì´í„° JSON ì œì™¸)
                    if not file_path.endswith('.csv'):
                        continue
                        
                    file_name = Path(file_path).name
                    verification_result = verifier.verify_single_file(f"backtest_data/processed/{file_name}")
                    
                    status = verification_result.get('status', 'unknown')
                    issues_count = len(verification_result.get('issues', []))
                    
                    if status == 'healthy':
                        print(f"âœ… Verification: {file_name} - HEALTHY ({issues_count} issues)")
                    else:
                        print(f"âš ï¸ Verification: {file_name} - {status.upper()} ({issues_count} issues)")
                        
                print("ğŸ¯ Data pipeline completed: collect â†’ save â†’ verify âœ…")
            
        else:
            print(f"âŒ Failed: {result.get('errors', [])}")
            
    except Exception as e:
        print(f"Error: {e}")

def list_data():
    """ìˆ˜ì§‘ëœ ë°ì´í„° ëª©ë¡"""
    print("ğŸ“Š Available backtest data:")
    
    try:
        from backtest.data_loader import BacktestDataLoader
        
        loader = BacktestDataLoader()
        available = loader.list_available_data()
        
        for file_type, files in available.items():
            print(f"\n{file_type.upper()} files:")
            for file in files:
                print(f"  - {file}")
                
        if not available:
            print("  No data files found. Use 'collect' command first.")
            
    except Exception as e:
        print(f"Error: {e}")

def analyze_data(filename):
    """ë°ì´í„° ë¶„ì„"""
    print(f"ğŸ“ˆ Analyzing {filename}...")
    
    try:
        from backtest.data_loader import BacktestDataLoader
        
        loader = BacktestDataLoader()
        df = loader.load_candles_from_file(filename)
        
        print(f"\nğŸ“Š Basic Info:")
        print(f"  â€¢ Size: {df.shape}")
        print(f"  â€¢ Period: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"  â€¢ Symbol: {df['symbol'].iloc[0]}")
        
        print(f"\nğŸ’° Price Info:")
        print(f"  â€¢ Start: {df.iloc[0]['close']:,.0f}ì›")
        print(f"  â€¢ End: {df.iloc[-1]['close']:,.0f}ì›")
        print(f"  â€¢ High: {df['high'].max():,.0f}ì›")
        print(f"  â€¢ Low: {df['low'].min():,.0f}ì›")
        
        change = ((df.iloc[-1]['close'] - df.iloc[0]['open']) / df.iloc[0]['open']) * 100
        print(f"  â€¢ Change: {change:+.2f}%")
        
        print(f"\nğŸ“Š Volume:")
        print(f"  â€¢ Total: {df['volume'].sum():.2f} {df['symbol'].iloc[0].split('-')[1]}")
        print(f"  â€¢ Average: {df['volume'].mean():.2f}")
        
    except Exception as e:
        print(f"Error: {e}")

def test_pipeline():
    """íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Testing pipeline...")
    
    try:
        from data_tools.test_pipeline import quick_pipeline_check
        quick_pipeline_check()
        
    except Exception as e:
        print(f"Error: {e}")

def main():
    parser = argparse.ArgumentParser(
        description="Adaptive Trading Bot CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ê¸°ë³¸ ì‚¬ìš©ë²• (í˜„ì¬ë¶€í„° Nì¼ ì „)
  python cli.py collect KRW-BTC 1h 3        # 3ì¼ ì „ë¶€í„° í˜„ì¬ê¹Œì§€
  
  # íŠ¹ì • ë‚ ì§œ ë²”ìœ„ ì§€ì •  
  python cli.py collect KRW-BTC 1h --start 2025-11-01 --end 2025-11-10
  python cli.py collect KRW-ETH 1d --start "2025-11-01 09:00"
  
  # ê¸°íƒ€ ëª…ë ¹ì–´
  python cli.py list                        # ë°ì´í„° íŒŒì¼ ëª©ë¡
  python cli.py analyze data.csv            # ë°ì´í„° ë¶„ì„
  python cli.py test                        # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Collect command
    collect_parser = subparsers.add_parser('collect', help='Collect market data')
    collect_parser.add_argument('symbol', help='Symbol (e.g., KRW-BTC)')
    collect_parser.add_argument('interval', help='Interval (e.g., 1h, 1d)')
    collect_parser.add_argument('days', type=int, nargs='?', default=1, 
                                help='Number of days (optional if using --start/--end)')
    
    # ë‚ ì§œ ë²”ìœ„ ì˜µì…˜ ì¶”ê°€
    collect_parser.add_argument('--start', type=str, 
                                help='Start date (YYYY-MM-DD or "YYYY-MM-DD HH:MM")')
    collect_parser.add_argument('--end', type=str,
                                help='End date (YYYY-MM-DD or "YYYY-MM-DD HH:MM")')
    
    # List command
    subparsers.add_parser('list', help='List available data files')
    
    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze data file')
    analyze_parser.add_argument('filename', help='Data file name')
    
    # Test command
    subparsers.add_parser('test', help='Test pipeline')
    
    args = parser.parse_args()
    
    if args.command == 'collect':
        collect_data(args.symbol, args.interval, args.days, args.start, args.end)
    elif args.command == 'list':
        list_data()
    elif args.command == 'analyze':
        analyze_data(args.filename)
    elif args.command == 'test':
        test_pipeline()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()